import numpy as np
import matplotlib.pyplot as plt
np.random.seed(0)
X_train_file_path=''
Y_train_file_path=''
X_test_file_path=''
#Parse csv files to numpy array
with open(X_train_file_path) as fp:
    next(fp)
    X_train=np.array([line.strip('\n').split(',')[1:] for line in fp],dtype=float)
with open(Y_train_file_path) as fp:
    next(fp)
    Y_train=np.array([line.strip('\n').split(',')[1] for line in fp],dtype=float)
with open(X_test_file_path) as fp:
    next(fp)
    X_test=np.array([line.strip('\n').split(',')[1] for line in fp],dtype=float)
def _normalize(X,train=True,specified_column=None,X_mean=None,X_std=None):
    #this function normalize specific colunms of X
    #the mean and standard variance of training data will be reused when processing
    #
    #Argunments:
    #   X:data to be processed
    #   train:'True'when processing training data,'False' for testing data
    #   specific_colunm;indexes of the colunms that will be normalized.If 'None' will be normalized.
    #   X_mean:mean value of training data,used when train='False'
    #   X_std:standard deviation of training data,used when train='False'
    #Outputs:
    #   X:normalized data
    #   X_mean:computed mean value of training data
    #   X_std:computed standard deviation of training data
    if specified_column==None:
        specified_column=np.arange(X.shape[1])
    if train:
        X_mean=np.mean(X[:,specified_column],0).reshape(1,-1)
        X_std=np.std(X[:,specified_column],0).reshape(1,-1)
    X[:, specified_column]=(X[:,specified_column]-X_mean)/(X_std+1e-8)

    return X,X_mean,X_std
def _train_dev_split(X,Y,dev_ratio=0.25):
    #this function splits data into training set and development set
    train_size=int(len(X)*(1-dev_ratio))
    return X[:train_size],Y[train_size],X[train_size:],Y[train_size:]
#Normalize training and testing data
X_train,X_mean,X_std=_normalize(X_train,train=True)
X_test=_normalize(X_test,train=False,X_mean=X_mean,X_std=X_std)

#Split data into training set and development set
dev_ratio=0.1
X_train,Y_train,X_dev,Y_dev=_train_dev_split(X_train,Y_train,dev_ratio=dev_ratio)

train_size=X_train.shape[0]
dev_size=X_dev.shape[0]
test_size=X_test.shape[0]
data_dim=X_train.shape[1]

def _shuffle(X,Y):
    #this function shuffle two equal_length list/array,X and Y,together
    randomize=np.arange(len(X))
    np.random.shuffle(randomize)
    return (X[randomize],Y[randomize])
def sigmoid(z):
    #sigmoid function can be used to calculate probability
    #to avoid overflow,minimum output value is set
    return np.clip(1/(1.0+np.exp(-z)),1e-8,1-(1e-8))

def _f(X,w,b):
    #this is the logistic regression function,parameterized by w and b
    #
    #Arguments:
    #   X:input data,shape=[batch_size,data_dimension]
    #   w:weight vector,shape=[data_dimension, ]
    #   b:bias,scalar
    #Outputs:
    #   predicted probability of each row of X being positively labeled,shape=[batch_size, ]
    return sigmoid(np.matmul(X,w)+b)
def _predict(X,w,b):
    #this function returns a truth value prediction for each row of X
    #by rounding the result of logistic regression function
    return np.round(_f(X,w,b)).astype(np.int)
def _accurancy(Y_pred,Y_label):
    #this function calculates prediction accurancy
    acc=1-np.mean(np.abs(Y_pred-Y_label))
    return acc
def _cross_entropy_loss(Y_pred,Y_label):
    #this function computes the cross entropy
    #
    #Arguments:
    #   Y_pred:probabilistic predictions, float vector
    #   Y_label:ground truth labels, bool vector
    #Outputs:
    #   cross entropy,scalar
    cross_entropy=-np.dot(Y_label,np.log(Y_pred))-np.dot((1-Y_label),np.log(1-Y_pred))
    return  cross_entropy
def _gradient(X,Y_label,w,b):
    #this function computes the gradient of cross entropy loss with respect to weight w and bias b
    Y_pred=_f(X,w,b)
    pred_error=Y_label-Y_pred
    w_grad=-np.sum(pred_error*X.T,1)
    b_grad=-np.sum(pred_error)
    return w_grad,b_grad
#Zero initialization for weights and bias
w=np.zeros((data_dim,1))
b=np.zeros((1,1))
#Some parameters for training
max_iter=10
batch_size=8
learning_rate=0.2
#keep the loss and entropy at every iteration for plotting
train_loss=[]
dev_loss=[]
train_acc=[]
dev_acc=[]
#Calculate the number of paramerter updates
step=1
#Iterative training
for i in range(max_iter):
    #Random shuffle at the begging of each epoch
    X_train,Y_train=_shuffle(X_train,Y_train)
    #Mini-batch training
    for idx in range(np.floor(train_size/batch_size)):
        X=X_train[idx*batch_szie:(idx+1)*batch_size]
        Y=Y_train[idx*batch_szie:(idx+1)*batch_size]

        #Compute the gradient
        w_grad,b_grad=_gradient(X,Y,w,b)

        #gradient descent update
        #learning_rate decay with time
        w=w-learning_rate/np.sqrt(step)*w_grad
        b=b-learning_rate/np.sqrt(step)*b_grad
        step=step+1

        #Compute loss and accurancy of training set and development set
        Y_train_pred=_f(X_train,w,b)
        Y_train_pred=np.round(Y_train_pred)
        train_acc.append(_accurancy(Y_train_pred,Y_train))
        train_loss.append(_cross_entropy_loss(Y_train_pred,Y_train)/train_size)

        Y_dev_pred=_f(X_dev,w,b)
        Y_dev_pred=np.round(Y_dev_pred)
        dev_acc.append(_accurancy(Y_dev_pred,Y_dev))
        dev_loss.append(_cross_entropy_loss(Y_dev_pred,Y_dev)/dev_size)

#Plotting Loss and accuracy curve
#Loss curve
plt.plot(train_loss)
plt.plot(dev_loss)
plt.title('Loss')
plt.legend(['train','dev'])
#plt.savefig('D:\\loss.png')
plt.show()

#Accuracy curve
plt.plot(train_acc)
plt.plot(dev_acc)
plt.title('Accuracy')
plt.legend(['train','dev'])
#plt.savefig('D:\\acc.png')
plt.show()

#Predict testing labels
predictions=_predict(X_test,w,b)
with open(output_fpath.format('logistic'),'w') as f:
    f.write('id,label\n')
    for i,label in enumerate(predictions):
        f.write('{},{}\n'.format(i,label))
#Print out the most significant weights
ind=np.argsort(np.abs(w))[::-1]
with open(X_test_file_path) as f:
    content=f.readline().strip('\n').split(',')
    features=np.array(content)
    for i in ind[0:10]:
        print(features[i],w[i])
#Porbabilistic generative model
#Compute in-class mean
X_train_0=np.array([x for x,y in zip(X_train,Y_train) if y==0])
X_train_1=np.array([x for x,y in zip(X_train,Y_train) if y==1])

mean_0=np.mean(X_train_0,axis=0)
mean_1=np.mean(X_train_1,axis=0)

#Compute in-class covariance
cov_0=np.zeros((data_dim,data_dim))
cov_1=np.zeros((data_dim,data_dim))

for x in X_train_0:
    cov_0+=np.dot(np.transpose([x-mean_0]),[x-mean_0])/X_train_0.shape[0]
for x in X_train_1:
    cov_1+=np.dot(np.transpose([x-mean_1]),[x-mean_1])/X_train_1.shape[0]
#shared covariance is taken as a weughted average of individual in-class covariance
cov=(cov_0*X_train_0.shape[0]+cov_1*X_train_1.shape[0])/(X_train_0.shape[0]+X_train_1.shape[0])
#Computing weights and bias
#Compute inverse of covariance matrix:
#Since covariance matrix may be nearly singular,np.linalg.inv() may give a large numerical error
#Via  SVD decomposition ,one can get matrix inverse effciently and accurately
u,s,v=np.linalg.svd(cov,full_matrices=False)
inv=np.matmul(v.T*1/,u.T)

#Directly compute weights and bias
w=np.dot(inv,mean_0-mean_1)
b=(-0.5)*np.dot(mean_0,np.dot(inv,mean_0))+0.5*np.dot(mean_1,np.dot(inv,mean_1))+np.log(float(X_train_0.shape[0])/X_train_1.shape[0])
#Compute accuracy on training set
Y_train_pred=1-_predict(X_train,w,b)
